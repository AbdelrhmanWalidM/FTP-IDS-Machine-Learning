{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14195910,"sourceType":"datasetVersion","datasetId":9052616}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\nimport glob\n\n# ==========================================\n# CONFIGURATION\n# ==========================================\nDATASET_FILE = '/kaggle/input/adsqwer/ftp_combined_dataset.csv'\n\ndef load_and_label_data():\n    if not os.path.exists(DATASET_FILE):\n        print(f\"ERROR: {DATASET_FILE} not found. Please run combine_csvs.py first.\")\n        return None\n        \n    print(f\"Loading {DATASET_FILE}...\")\n    df = pd.read_csv(DATASET_FILE)\n    \n    # Auto-labeling Logic\n    # The file already has 'label' (0 or 1) from the merge script.\n    # We just need to refine the attack labels:\n    \n    # Label = 1 (Brute Force) - Default for attack files\n    \n    # Refine Label = 2 (Post Exploit) if command is suspicious\n    # We only apply this to rows that are ALREADY marked as attack (label=1)\n    # to avoid false positives if a normal user does a LIST (though unlikely in this lab setup)\n    post_exploit_cmds = ['RETR', 'STOR', 'DELE', 'MKD', 'RMD', 'SITE']\n    df.loc[(df['label'] == 1) & (df['ftp.request.command'].isin(post_exploit_cmds)), 'label'] = 2\n    \n    print(f\"Data Distribution:\\n{df['label'].value_counts()}\")\n    \n    return df\n\ndef preprocess_data(df):\n    print(\"Preprocessing data...\")\n    \n    # Fill NaNs\n    df.fillna({'ftp.request.command': 'NONE', 'ftp.response.code': 0, 'ftp.response.arg': 'NONE'}, inplace=True)\n    \n    # Feature Engineering\n    # Encode categorical columns\n    le_cmd = LabelEncoder()\n    df['ftp.command_enc'] = le_cmd.fit_transform(df['ftp.request.command'].astype(str))\n    \n    # FIX: Encode TCP flags if they are strings (e.g. 'PA', 'A')\n    le_flags = LabelEncoder()\n    df['tcp.flags_enc'] = le_flags.fit_transform(df['tcp.flags'].astype(str))\n    \n    # We can also use packet length and flags\n    # We drop IPs for the model to generalize (avoid learning specific IP addresses)\n    # UPDATED: Use the encoded flags instead of the raw string flags\n    features = ['frame.len', 'tcp.srcport', 'tcp.dstport', 'tcp.flags_enc', 'ftp.command_enc', 'ftp.response.code']\n    \n    X = df[features]\n    y = df['label']\n    \n    return X, y\n\ndef train_model(X, y):\n    print(\"Training Random Forest Model...\")\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42,stratify=y)\n    \n    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n    clf.fit(X_train, y_train)\n    \n    print(\"Model Training Complete.\")\n    \n    # Evaluation\n    y_pred = clf.predict(X_test)\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_test, y_pred, target_names=['Benign', 'BruteForce', 'PostExploit'] if 2 in y.values else ['Benign', 'Attack']))\n    \n    return clf\n\nif __name__ == \"__main__\":\n    df = load_and_label_data()\n    if df is not None and len(df) > 0:\n        X, y = preprocess_data(df)\n        model = train_model(X, y)\n        print(\"\\nDone! The model is trained and ready.\")\n        \n        # Example prediction\n        print(\"\\nTest Prediction (Simulated 'RETR' command):\")\n        # Construct a fake input matching our features: len=100, ports=random, flags=24(PA), cmd='RETR', code=226\n        # Note: You would need to handle the LabelEncoder transformation properly in production\n        pass\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T13:57:41.276870Z","iopub.execute_input":"2025-12-17T13:57:41.277540Z","iopub.status.idle":"2025-12-17T13:57:44.412414Z","shell.execute_reply.started":"2025-12-17T13:57:41.277506Z","shell.execute_reply":"2025-12-17T13:57:44.411602Z"}},"outputs":[{"name":"stdout","text":"Loading /kaggle/input/adsqwer/ftp_combined_dataset.csv...\nData Distribution:\nlabel\n1    11348\n0     1869\n2       27\nName: count, dtype: int64\nPreprocessing data...\nTraining Random Forest Model...\nModel Training Complete.\n\nClassification Report:\n              precision    recall  f1-score   support\n\n      Benign       0.68      0.64      0.66       561\n  BruteForce       0.94      0.95      0.95      3405\n PostExploit       0.78      0.88      0.82         8\n\n    accuracy                           0.91      3974\n   macro avg       0.80      0.82      0.81      3974\nweighted avg       0.90      0.91      0.91      3974\n\n\nDone! The model is trained and ready.\n\nTest Prediction (Simulated 'RETR' command):\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ==========================================================\n# FTP Intrusion Detection using Time‑Window Aggregation\n# ==========================================================\n\nimport pandas as pd\nimport numpy as np\nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# ==========================================================\n# CONFIGURATION\n# ==========================================================\nDATASET_FILE = '/kaggle/input/adsqwer/ftp_combined_dataset.csv'\n# TIME_WINDOW = '5s'   # 2s, 5s, 10s (try multiple)\n# TIME_WINDOW = '2s'\n# TIME_WINDOW = '5s'\nTIME_WINDOW = '10s'\n\nPOST_EXPLOIT_CMDS = ['RETR', 'STOR', 'DELE', 'MKD', 'RMD', 'SITE']\n\n# ==========================================================\n# LOAD + AUTO LABEL\n# ==========================================================\ndef load_and_label_data():\n    if not os.path.exists(DATASET_FILE):\n        raise FileNotFoundError(f\"{DATASET_FILE} not found\")\n\n    print(f\"[+] Loading dataset: {DATASET_FILE}\")\n    df = pd.read_csv(DATASET_FILE)\n\n    # Ensure numeric timestamp\n    df['frame.time_epoch'] = pd.to_numeric(\n        df['frame.time_epoch'], errors='coerce'\n    )\n\n    # Fill missing fields\n    df.fillna({\n        'ftp.request.command': 'NONE',\n        'ftp.response.code': 0,\n        'tcp.flags': 'NONE'\n    }, inplace=True)\n\n    # Refine post‑exploit label\n    df.loc[\n        (df['label'] == 1) &\n        (df['ftp.request.command'].isin(POST_EXPLOIT_CMDS)),\n        'label'\n    ] = 2\n\n    print(\"\\n[+] Label distribution:\")\n    print(df['label'].value_counts())\n\n    return df\n\n\n# ==========================================================\n# TIME WINDOW FEATURE ENGINEERING\n# ==========================================================\ndef create_time_window_features(df, window_size='5s'):\n    print(f\"\\n[+] Creating time‑window features ({window_size})\")\n\n    df = df.copy()\n\n    # Create flow identifier\n    df['flow_id'] = (\n        df['tcp.srcport'].astype(str) + \"_\" +\n        df['tcp.dstport'].astype(str)\n    )\n\n    # Convert timestamp\n    df['timestamp'] = pd.to_datetime(df['frame.time_epoch'], unit='s')\n    df = df.sort_values('timestamp')\n\n    windows = []\n\n    # Convert string window_size like '5s' → Timedelta\n    td_window = pd.to_timedelta(window_size)\n\n    for flow, g in df.groupby('flow_id'):\n        g = g.sort_values('timestamp')\n        start_time = g['timestamp'].min()\n\n        # Create a moving window manually\n        current_start = start_time\n        while current_start <= g['timestamp'].max():\n            current_end = current_start + td_window\n            window_rows = g[(g['timestamp'] >= current_start) & (g['timestamp'] < current_end)]\n\n            if len(window_rows) == 0:\n                current_start = current_end\n                continue\n\n            row = {\n                'pkt_count': len(window_rows),\n                'bytes_sum': window_rows['frame.len'].sum(),\n                'bytes_mean': window_rows['frame.len'].mean(),\n                'user_cmd_count': (window_rows['ftp.request.command'] == 'USER').sum(),\n                'pass_cmd_count': (window_rows['ftp.request.command'] == 'PASS').sum(),\n                'post_exploit_cmd_count': window_rows['ftp.request.command'].isin(POST_EXPLOIT_CMDS).sum(),\n                'login_success_count': (window_rows['ftp.response.code'] == 230).sum(),\n                'syn_count': (window_rows['tcp.flags'] == 'S').sum(),\n                'pa_count': (window_rows['tcp.flags'] == 'PA').sum(),\n                'label': window_rows['label'].mode()[0]  # majority label\n            }\n\n            windows.append(row)\n            current_start = current_end\n\n    windowed_df = pd.DataFrame(windows)\n    print(f\"[+] Generated {len(windowed_df)} window samples\")\n    return windowed_df\n\n# ==========================================================\n# TRAIN + EVALUATE MODEL\n# ==========================================================\ndef train_model(df_windowed):\n    print(\"\\n[+] Training model\")\n\n    X = df_windowed.drop(columns=['label'])\n    y = df_windowed['label']\n\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y,\n        test_size=0.3,\n        random_state=42,\n        stratify=y\n    )\n\n    clf = RandomForestClassifier(\n        n_estimators=200,\n        max_depth=12,\n        random_state=42,\n        class_weight='balanced'\n    )\n\n    clf.fit(X_train, y_train)\n\n    print(\"[+] Model training complete\")\n\n    y_pred = clf.predict(X_test)\n\n    print(\"\\n===== Classification Report =====\")\n    unique_labels = sorted(y_test.unique())\n    target_names = []\n    for lbl in unique_labels:\n        if lbl == 0:\n            target_names.append('Benign')\n        elif lbl == 1:\n            target_names.append('BruteForce')\n        else:\n            target_names.append('PostExploit')\n    \n    print(classification_report(y_test, y_pred, target_names=target_names))\n    print(\"\\n===== Confusion Matrix =====\")\n    print(confusion_matrix(y_test, y_pred))\n\n    return clf\n\n\n# ==========================================================\n# MAIN\n# ==========================================================\n# if __name__ == \"__main__\":\ndf = load_and_label_data()\ndf_windowed = create_time_window_features(df, TIME_WINDOW)\nmodel = train_model(df_windowed)\n\nprint(\"\\n[✓] FTP IDS model is ready!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T14:29:32.307622Z","iopub.execute_input":"2025-12-17T14:29:32.308087Z"}},"outputs":[{"name":"stdout","text":"[+] Loading dataset: /kaggle/input/adsqwer/ftp_combined_dataset.csv\n\n[+] Label distribution:\nlabel\n1    11348\n0     1869\n2       27\nName: count, dtype: int64\n\n[+] Creating time‑window features (10s)\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}